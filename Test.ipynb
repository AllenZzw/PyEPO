{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naval-blade",
   "metadata": {},
   "source": [
    "## Optimization model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accredited-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import shortestPathModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-04-13\n",
      "Using license file C:\\Users\\Apocrypse\\gurobi.lic\n"
     ]
    }
   ],
   "source": [
    "# model for shortest path\n",
    "grid = (5,5)\n",
    "sp_model = shortestPathModel(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precious-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj: 8.0\n",
      "(0, 1)\n",
      "(1, 2)\n",
      "(2, 3)\n",
      "(3, 4)\n",
      "(4, 9)\n",
      "(9, 14)\n",
      "(14, 19)\n",
      "(19, 24)\n"
     ]
    }
   ],
   "source": [
    "# solve\n",
    "sp_model.setObj([1 for i in range(40)])\n",
    "sol, obj = sp_model.solve()\n",
    "print('Obj: {}'.format(obj))\n",
    "for i, e in enumerate(sp_model.arcs):\n",
    "    if sol[i] > 1e-3:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-consultancy",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "little-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import shortestpath, dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relative-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for grid network (features and costs)\n",
    "n = 1000\n",
    "p = 5\n",
    "x, c = shortestpath.genData(n, p, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opposite-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=0.2, random_state=246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "human-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 800/800 [00:01<00:00, 402.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# get training data set\n",
    "sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nonprofit-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 423.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# get training data set\n",
    "sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incident-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "sp_loader_train = DataLoader(sp_dataset_train, batch_size=32, shuffle=True)\n",
    "sp_loader_test = DataLoader(sp_dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intellectual-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(sp_loader_train):\n",
    "    x, c, w, z = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instant-polymer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "known-framing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "partial-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "known-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-consequence",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authentic-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import SPOPlusLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "directed-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init SPO+ loss\n",
    "criterion = SPOPlusLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-queue",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "shaped-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fresh-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(p, (grid[0] - 1) * grid[1] + (grid[1] - 1) * grid[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interior-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "lr = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    lr = lr.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-clerk",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "asian-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "optimizer = torch.optim.SGD(lr.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "framed-classification",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss:7.913526\n",
      "epoch 1, loss:10.170893\n",
      "epoch 2, loss:9.177206\n",
      "epoch 3, loss:7.889743\n",
      "epoch 4, loss:9.879528\n",
      "epoch 5, loss:7.333094\n",
      "epoch 6, loss:7.931744\n",
      "epoch 7, loss:8.710623\n",
      "epoch 8, loss:7.919879\n",
      "epoch 9, loss:8.295485\n",
      "epoch 10, loss:6.961536\n",
      "epoch 11, loss:6.963871\n",
      "epoch 12, loss:7.419167\n",
      "epoch 13, loss:7.247763\n",
      "epoch 14, loss:7.287656\n",
      "epoch 15, loss:6.196450\n",
      "epoch 16, loss:6.447455\n",
      "epoch 17, loss:5.998956\n",
      "epoch 18, loss:6.426476\n",
      "epoch 19, loss:5.210809\n",
      "epoch 20, loss:5.696073\n",
      "epoch 21, loss:5.181269\n",
      "epoch 22, loss:5.261272\n",
      "epoch 23, loss:5.443936\n",
      "epoch 24, loss:5.976016\n",
      "epoch 25, loss:5.324244\n",
      "epoch 26, loss:5.135509\n",
      "epoch 27, loss:4.404396\n",
      "epoch 28, loss:4.832863\n",
      "epoch 29, loss:4.791393\n",
      "epoch 30, loss:4.749573\n",
      "epoch 31, loss:4.612350\n",
      "epoch 32, loss:5.344852\n",
      "epoch 33, loss:4.019475\n",
      "epoch 34, loss:4.444191\n",
      "epoch 35, loss:4.220982\n",
      "epoch 36, loss:3.813695\n",
      "epoch 37, loss:4.022830\n",
      "epoch 38, loss:3.652021\n",
      "epoch 39, loss:3.510758\n",
      "epoch 40, loss:2.849797\n",
      "epoch 41, loss:3.650493\n",
      "epoch 42, loss:4.727657\n",
      "epoch 43, loss:2.643980\n",
      "epoch 44, loss:3.083940\n",
      "epoch 45, loss:3.373317\n",
      "epoch 46, loss:3.659322\n",
      "epoch 47, loss:2.776425\n",
      "epoch 48, loss:2.893017\n",
      "epoch 49, loss:2.518502\n",
      "epoch 50, loss:2.150459\n",
      "epoch 51, loss:2.209208\n",
      "epoch 52, loss:2.296602\n",
      "epoch 53, loss:2.347193\n",
      "epoch 54, loss:2.550676\n",
      "epoch 55, loss:2.651073\n",
      "epoch 56, loss:2.467442\n",
      "epoch 57, loss:1.883523\n",
      "epoch 58, loss:2.383727\n",
      "epoch 59, loss:2.371679\n",
      "epoch 60, loss:2.014156\n",
      "epoch 61, loss:1.522453\n",
      "epoch 62, loss:2.282518\n",
      "epoch 63, loss:1.789529\n",
      "epoch 64, loss:2.208686\n",
      "epoch 65, loss:1.568855\n",
      "epoch 66, loss:1.487656\n",
      "epoch 67, loss:2.036017\n",
      "epoch 68, loss:1.765975\n",
      "epoch 69, loss:1.546211\n",
      "epoch 70, loss:1.742103\n",
      "epoch 71, loss:1.707925\n",
      "epoch 72, loss:1.704585\n",
      "epoch 73, loss:1.203242\n",
      "epoch 74, loss:1.760767\n",
      "epoch 75, loss:2.065325\n",
      "epoch 76, loss:1.150094\n",
      "epoch 77, loss:1.047940\n",
      "epoch 78, loss:1.079998\n",
      "epoch 79, loss:1.617334\n",
      "epoch 80, loss:0.983829\n",
      "epoch 81, loss:0.949589\n",
      "epoch 82, loss:0.903473\n",
      "epoch 83, loss:0.772257\n",
      "epoch 84, loss:0.971085\n",
      "epoch 85, loss:0.541511\n",
      "epoch 86, loss:1.069912\n",
      "epoch 87, loss:1.276318\n",
      "epoch 88, loss:1.113942\n",
      "epoch 89, loss:0.658282\n",
      "epoch 90, loss:0.798369\n",
      "epoch 91, loss:0.819008\n",
      "epoch 92, loss:1.216766\n",
      "epoch 93, loss:0.737044\n",
      "epoch 94, loss:0.575867\n",
      "epoch 95, loss:0.486253\n",
      "epoch 96, loss:0.642164\n",
      "epoch 97, loss:0.801304\n",
      "epoch 98, loss:1.104258\n",
      "epoch 99, loss:0.801587\n",
      "epoch 100, loss:1.186773\n",
      "epoch 101, loss:0.692473\n",
      "epoch 102, loss:0.769844\n",
      "epoch 103, loss:0.868418\n",
      "epoch 104, loss:1.223978\n",
      "epoch 105, loss:0.643295\n",
      "epoch 106, loss:0.774025\n",
      "epoch 107, loss:0.509787\n",
      "epoch 108, loss:0.955560\n",
      "epoch 109, loss:0.599941\n",
      "epoch 110, loss:0.530277\n",
      "epoch 111, loss:1.070981\n",
      "epoch 112, loss:0.751052\n",
      "epoch 113, loss:0.441506\n",
      "epoch 114, loss:0.684742\n",
      "epoch 115, loss:0.471820\n",
      "epoch 116, loss:0.320621\n",
      "epoch 117, loss:0.317234\n",
      "epoch 118, loss:0.771641\n",
      "epoch 119, loss:0.416110\n",
      "epoch 120, loss:0.577138\n",
      "epoch 121, loss:0.485136\n",
      "epoch 122, loss:0.820471\n",
      "epoch 123, loss:0.944402\n",
      "epoch 124, loss:0.347427\n",
      "epoch 125, loss:0.829194\n",
      "epoch 126, loss:0.546111\n",
      "epoch 127, loss:0.697957\n",
      "epoch 128, loss:0.392562\n",
      "epoch 129, loss:0.810053\n",
      "epoch 130, loss:0.801618\n",
      "epoch 131, loss:0.782930\n",
      "epoch 132, loss:0.752410\n",
      "epoch 133, loss:0.561404\n",
      "epoch 134, loss:0.411537\n",
      "epoch 135, loss:0.639161\n",
      "epoch 136, loss:0.554477\n",
      "epoch 137, loss:0.394548\n",
      "epoch 138, loss:0.510943\n",
      "epoch 139, loss:0.371338\n",
      "epoch 140, loss:0.592832\n",
      "epoch 141, loss:0.699078\n",
      "epoch 142, loss:0.488469\n",
      "epoch 143, loss:0.307632\n",
      "epoch 144, loss:0.160665\n",
      "epoch 145, loss:0.486128\n",
      "epoch 146, loss:0.564455\n",
      "epoch 147, loss:0.277289\n",
      "epoch 148, loss:0.506810\n",
      "epoch 149, loss:0.403187\n",
      "epoch 150, loss:0.788995\n",
      "epoch 151, loss:1.133397\n",
      "epoch 152, loss:0.586801\n",
      "epoch 153, loss:0.275790\n",
      "epoch 154, loss:0.336217\n",
      "epoch 155, loss:0.114173\n",
      "epoch 156, loss:0.333866\n",
      "epoch 157, loss:0.758018\n",
      "epoch 158, loss:0.706524\n",
      "epoch 159, loss:0.376344\n",
      "epoch 160, loss:0.363559\n",
      "epoch 161, loss:0.608910\n",
      "epoch 162, loss:0.245889\n",
      "epoch 163, loss:0.635537\n",
      "epoch 164, loss:0.055495\n",
      "epoch 165, loss:0.359303\n",
      "epoch 166, loss:0.659970\n",
      "epoch 167, loss:0.554041\n",
      "epoch 168, loss:0.648733\n",
      "epoch 169, loss:0.595995\n",
      "epoch 170, loss:0.507366\n",
      "epoch 171, loss:0.516192\n",
      "epoch 172, loss:0.300815\n",
      "epoch 173, loss:0.819052\n",
      "epoch 174, loss:0.389669\n",
      "epoch 175, loss:0.291793\n",
      "epoch 176, loss:0.444723\n",
      "epoch 177, loss:0.293083\n",
      "epoch 178, loss:0.328912\n",
      "epoch 179, loss:0.195489\n",
      "epoch 180, loss:0.114769\n",
      "epoch 181, loss:0.590694\n",
      "epoch 182, loss:0.577332\n",
      "epoch 183, loss:0.689736\n",
      "epoch 184, loss:0.236782\n",
      "epoch 185, loss:0.197567\n",
      "epoch 186, loss:0.491773\n",
      "epoch 187, loss:0.738003\n",
      "epoch 188, loss:0.321807\n",
      "epoch 189, loss:0.318472\n",
      "epoch 190, loss:0.259249\n",
      "epoch 191, loss:0.221632\n",
      "epoch 192, loss:0.351279\n",
      "epoch 193, loss:0.331341\n",
      "epoch 194, loss:0.160761\n",
      "epoch 195, loss:0.128760\n",
      "epoch 196, loss:0.282537\n",
      "epoch 197, loss:0.273426\n",
      "epoch 198, loss:0.219140\n",
      "epoch 199, loss:0.566111\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # load data\n",
    "    for i, data in enumerate(sp_loader_train):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = lr(x)\n",
    "        loss = criterion.apply(sp_model, cp, c, w, z).mean()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print('epoch {}, loss:{:.6f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-thought",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
