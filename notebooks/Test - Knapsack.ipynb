{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1bcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set work dir\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8178d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x258e670fbf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pyepo\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.reload_library()\n",
    "plt.style.use(\"science\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(135)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610273f3",
   "metadata": {},
   "source": [
    "## Init Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b294594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for grid network (features and costs)\n",
    "m = 48 # number of items\n",
    "n = 100 # number of data\n",
    "p = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "dim = 2 # dimension of knapsack\n",
    "noise_width = 0.5 # noise half-width\n",
    "caps = [30] * dim # capacity\n",
    "weights, x, c = pyepo.data.knapsack.genData(n+1000, p, m, deg=deg, dim=dim, noise_width=noise_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1f8e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.59, 4.87, 5.19, 7.59, 6.8 , 4.97, 4.84, 3.22, 7.9 , 3.62, 3.12,\n",
       "        6.81, 7.09, 3.23, 4.47, 5.23, 6.11, 5.23, 4.27, 6.66, 5.21, 3.72,\n",
       "        7.83, 5.64, 7.56, 3.28, 4.31, 3.85, 6.43, 4.26, 7.56, 6.4 , 6.09,\n",
       "        6.4 , 4.5 , 6.31, 6.35, 3.07, 6.03, 7.39, 3.48, 5.57, 6.27, 4.55,\n",
       "        5.64, 5.66, 3.27, 6.68],\n",
       "       [4.2 , 5.61, 6.13, 7.88, 4.61, 4.92, 6.09, 7.95, 7.11, 4.02, 3.07,\n",
       "        7.84, 6.29, 5.78, 5.57, 5.65, 7.41, 5.21, 3.42, 6.48, 5.77, 7.67,\n",
       "        7.32, 3.31, 4.36, 4.75, 3.38, 3.44, 6.3 , 4.85, 7.09, 5.7 , 4.05,\n",
       "        6.04, 6.51, 3.41, 7.94, 6.05, 7.18, 3.64, 4.35, 4.45, 4.27, 4.87,\n",
       "        5.74, 3.16, 5.41, 3.81]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2586e",
   "metadata": {},
   "source": [
    "## Optimization Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c1fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "\n",
      "--------------------------------------------\n",
      "Warning: your license will expire in 5 days\n",
      "--------------------------------------------\n",
      "\n",
      "Academic license - for non-commercial use only - expires 2022-03-06\n"
     ]
    }
   ],
   "source": [
    "ks_model = pyepo.model.grb.knapsackModel(weights, caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e5bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Obj: 265.0\n",
      "40\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# solve\n",
    "ks_model.setObj([i for i in range(m)])\n",
    "sol, obj = ks_model.solve()\n",
    "print(sol)\n",
    "print(\"Obj: {}\".format(obj))\n",
    "for i in ks_model.items:\n",
    "    if sol[i] > 1e-3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a11572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relax\n",
    "ks_model_rel = ks_model.relax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c09dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9225932025752352, 0.0, 0.0, 1.0, 0.6333283425662526, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n",
      "Obj: 281.10241054050005\n",
      "37\n",
      "40\n",
      "41\n",
      "43\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# solve\n",
    "ks_model_rel.setObj([i for i in range(m)])\n",
    "sol, obj = ks_model_rel.solve()\n",
    "print(sol)\n",
    "print(\"Obj: {}\".format(obj))\n",
    "for i in ks_model_rel.items:\n",
    "    if sol[i] > 1e-3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec37e4",
   "metadata": {},
   "source": [
    "## Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261aed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eda340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e0ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 236.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# get training data set\n",
    "ks_dataset_train = pyepo.data.dataset.optDataset(ks_model, x_train, c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad71155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 746.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# get training data set for relaxation\n",
    "ks_dataset_train_rel = pyepo.data.dataset.optDataset(ks_model_rel, x_train, c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fc0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 171.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# get test data set\n",
    "ks_dataset_test = pyepo.data.dataset.optDataset(ks_model, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0bbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "batch_size = 32\n",
    "ks_loader_train = DataLoader(ks_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "ks_loader_train_rel = DataLoader(ks_dataset_train_rel, batch_size=batch_size, shuffle=True)\n",
    "ks_loader_test = DataLoader(ks_dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a542a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(ks_loader_train):\n",
    "    x, c, w, z = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75fc2763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e50a821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074c9398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20de02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba836667",
   "metadata": {},
   "source": [
    "## Linear Regression from Scikit-Lear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bac0dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2888cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19e83e",
   "metadata": {},
   "source": [
    "## Two-Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6adcf558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "twostage_model = pyepo.twostage.sklearnPred(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86fe3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=LinearRegression())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "twostage_model.fit(ks_dataset_train.feats, ks_dataset_train.costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e103e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "c_test_pred = twostage_model.predict(ks_dataset_test.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa3cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:25<00:00, 38.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized true SPO Loss: 12.45%\n",
      "Normalized unambiguous SPO Loss: 12.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "truespo = 0\n",
    "unambspo = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    c_pred_i = c_test_pred[i]\n",
    "    c_true_i = ks_dataset_test.costs[i]\n",
    "    z_true_i = ks_dataset_test.objs[i,0]\n",
    "    truespo += pyepo.metric.calRegret(ks_model, c_pred_i, c_true_i, z_true_i)\n",
    "    unambspo += pyepo.metric.calUnambRegret(ks_model, c_pred_i, c_true_i, z_true_i)\n",
    "time.sleep(1)\n",
    "print(\"Normalized true SPO Loss: {:.2f}%\".format(truespo / abs(ks_dataset_test.objs.sum()) * 100))\n",
    "print(\"Normalized unambiguous SPO Loss: {:.2f}%\".format(unambspo / abs(ks_dataset_test.objs.sum()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feeeed33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "    True cost: 2.00, 4.00, 1.00, 1.00, 2.00, 1.00, 2.00, 1.00, 1.00, 2.00, 5.00, 1.00, 1.00, 5.00, 3.00, 2.00, 1.00, 2.00, 3.00, 3.00, 1.00, 1.00, 1.00, 1.00, 3.00, 3.00, 2.00, 2.00, 1.00, 2.00, 2.00, 2.00, 3.00, 1.00, 4.00, 2.00, 1.00, 3.00, 4.00, 1.00, 2.00, 4.00, 1.00, 2.00, 3.00, 1.00, 5.00, 2.00\n",
      "    Pred cost: 1.53, 4.22, 1.01, 0.43, 1.73, 0.37, 1.77, 1.53, 0.90, 1.17, 4.08, 1.57, 0.99, 4.51, 2.95, 1.91, 1.86, 1.74, 3.12, 2.99, 1.30, 0.98, 1.57, 0.53, 3.14, 2.77, 2.31, 3.00, 1.26, 1.70, 1.55, 1.49, 3.77, 1.11, 3.58, 3.87, 1.37, 3.00, 3.01, 1.12, 1.64, 3.89, 1.39, 3.84, 2.86, 1.17, 3.84, 1.32\n",
      "    True sol: -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, 1, -0, True obj: 27.00\n",
      "    Pred sol: -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, 1, -0, Pred obj: 26.00\n",
      "\n",
      "Sample 1:\n",
      "    True cost: 4.00, 1.00, 5.00, 8.00, 4.00, 3.00, 2.00, 5.00, 2.00, 6.00, 1.00, 6.00, 7.00, 3.00, 7.00, 2.00, 6.00, 4.00, 2.00, 7.00, 3.00, 3.00, 3.00, 5.00, 3.00, 7.00, 2.00, 5.00, 3.00, 4.00, 2.00, 5.00, 7.00, 3.00, 4.00, 7.00, 5.00, 7.00, 2.00, 5.00, 6.00, 1.00, 3.00, 5.00, 11.00, 3.00, 2.00, 5.00\n",
      "    Pred cost: 6.71, -0.19, 7.13, 7.98, 8.24, 8.44, 4.35, 4.67, 3.42, 6.23, -0.37, 4.60, 7.07, 2.27, 6.49, 1.53, 7.79, 7.80, 1.09, 7.63, 3.28, 6.50, 3.19, 9.50, 3.03, 6.71, 1.49, 7.38, 4.89, 4.65, 2.22, 6.03, 6.37, 6.88, 4.12, 6.24, 6.16, 6.99, 1.30, 6.82, 4.82, 0.10, 3.27, 6.84, 7.61, 5.38, 1.80, 8.34\n",
      "    True sol: 0, 0, 0, 0, 0, 0, 0, 0, -0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, -0, 0, 0, 1, 0, 0, 0, 0, -0, 0, 1, 0, 0, 1, 0, 1, -0, 0, 0, 0, 0, 0, 1, 0, 0, 0, True obj: 46.00\n",
      "    Pred sol: -0, 0, -0, -0, 0, 0, -0, -0, -0, 1, 0, -0, -0, -0, 0, -0, -0, 0, -0, -0, -0, -0, -0, 1, -0, 1, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, 0, -0, -0, -0, 1, Pred obj: 41.00\n",
      "\n",
      "Sample 2:\n",
      "    True cost: 8.00, 7.00, 9.00, 7.00, 6.00, 6.00, 12.00, 6.00, 10.00, 12.00, 5.00, 10.00, 7.00, 6.00, 1.00, 12.00, 8.00, 14.00, 4.00, 2.00, 10.00, 12.00, 7.00, 3.00, 3.00, 2.00, 17.00, 2.00, 6.00, 4.00, 9.00, 12.00, 5.00, 12.00, 4.00, 3.00, 12.00, 3.00, 3.00, 11.00, 8.00, 6.00, 8.00, 4.00, 2.00, 5.00, 4.00, 7.00\n",
      "    Pred cost: 12.28, 7.29, 12.25, 7.46, 10.48, 8.06, 8.97, 6.43, 8.53, 13.52, 7.81, 6.30, 7.87, 5.46, 2.84, 12.42, 8.88, 9.01, 3.95, 1.74, 7.80, 12.47, 7.85, 7.69, 3.14, 2.69, 10.43, 1.82, 6.83, 6.99, 11.72, 11.51, 5.27, 11.24, 5.64, 5.51, 10.74, 2.37, 4.31, 12.06, 6.83, 8.21, 7.63, 5.28, 2.36, 6.30, 5.80, 10.65\n",
      "    True sol: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, True obj: 78.00\n",
      "    Pred sol: 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -0, 0, 0, 0, 1, 0, 0, 0, -0, 0, 1, 0, 0, -0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0, 1, 0, 0, 0, 0, -0, 0, 0, 0, Pred obj: 72.00\n",
      "\n",
      "Sample 3:\n",
      "    True cost: 2.00, 4.00, 1.00, 2.00, 2.00, 1.00, 2.00, 3.00, 1.00, 1.00, 3.00, 3.00, 2.00, 3.00, 3.00, 3.00, 2.00, 2.00, 1.00, 2.00, 3.00, 1.00, 2.00, 2.00, 2.00, 1.00, 1.00, 1.00, 1.00, 2.00, 1.00, 2.00, 2.00, 1.00, 3.00, 2.00, 1.00, 4.00, 3.00, 1.00, 2.00, 4.00, 2.00, 2.00, 2.00, 2.00, 3.00, 1.00\n",
      "    Pred cost: 2.82, 4.24, 0.71, 0.49, 2.33, 0.46, 1.11, 2.28, 0.78, 2.32, 3.89, 2.40, 2.15, 3.80, 3.11, 2.73, 2.03, 2.21, 2.47, 1.61, 2.18, 0.78, 2.74, 0.23, 3.12, 1.72, 3.06, 1.96, 0.93, 2.40, 0.92, 2.22, 3.26, 0.69, 3.49, 2.20, 1.02, 3.05, 3.36, 0.96, 2.46, 3.90, 2.48, 2.20, 1.74, 1.07, 3.46, 0.68\n",
      "    True sol: 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, True obj: 20.00\n",
      "    Pred sol: 1, 1, -0, -0, 0, -0, -0, -0, -0, 0, 1, -0, -0, 1, 0, 0, -0, 0, 1, -0, 0, -0, -0, -0, 0, 0, 1, 0, -0, 0, -0, 0, 0, -0, 0, 0, -0, 0, 0, -0, 0, 1, 0, 0, -0, 0, 0, -0, Pred obj: 18.00\n",
      "\n",
      "Sample 4:\n",
      "    True cost: 4.00, 3.00, 3.00, 2.00, 5.00, 4.00, 13.00, 11.00, 5.00, 4.00, 2.00, 9.00, 4.00, 3.00, 3.00, 7.00, 9.00, 9.00, 2.00, 4.00, 4.00, 5.00, 3.00, 8.00, 2.00, 3.00, 6.00, 4.00, 10.00, 10.00, 5.00, 4.00, 4.00, 4.00, 2.00, 3.00, 6.00, 2.00, 1.00, 6.00, 10.00, 1.00, 5.00, 4.00, 3.00, 9.00, 5.00, 7.00\n",
      "    Pred cost: 5.72, 0.29, 8.06, 5.90, 9.41, 7.22, 8.78, 6.97, 6.09, 6.55, 1.70, 6.57, 5.42, 3.94, 3.54, 5.15, 8.49, 8.01, 0.33, 4.12, 5.08, 8.02, 5.02, 10.53, 3.06, 4.25, 4.78, 3.83, 8.53, 7.37, 7.11, 6.45, 4.44, 8.54, 0.94, 5.33, 7.54, 3.10, 0.63, 7.61, 7.36, 1.85, 4.33, 5.55, 4.82, 8.29, 3.87, 11.10\n",
      "    True sol: 0, -0, -0, -0, -0, -0, 1, 1, -0, 0, 0, 0, -0, -0, -0, 0, 0, 0, -0, -0, -0, -0, -0, 1, -0, -0, 0, 0, 0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, 0, 1, -0, 0, -0, -0, 1, 0, 0, True obj: 61.00\n",
      "    Pred sol: -0, -0, 0, -0, 0, -0, 1, 1, -0, 0, -0, -0, -0, -0, -0, -0, -0, 0, -0, -0, -0, 0, -0, 1, -0, -0, -0, -0, -0, 0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, 1, -0, 1, Pred obj: 58.00\n",
      "\n",
      "Sample 5:\n",
      "    True cost: 1.00, 1.00, 1.00, 1.00, 2.00, 1.00, 2.00, 3.00, 2.00, 1.00, 2.00, 2.00, 1.00, 3.00, 3.00, 1.00, 2.00, 2.00, 2.00, 4.00, 2.00, 1.00, 1.00, 1.00, 5.00, 3.00, 1.00, 3.00, 2.00, 2.00, 1.00, 1.00, 2.00, 1.00, 1.00, 4.00, 1.00, 4.00, 2.00, 1.00, 2.00, 1.00, 1.00, 4.00, 3.00, 2.00, 4.00, 2.00\n",
      "    Pred cost: -0.09, 1.33, 0.33, 0.93, 2.06, 1.19, 2.03, 2.16, 0.55, -0.58, 1.48, 2.11, 0.99, 3.60, 3.56, -0.49, 2.35, 2.05, 1.76, 4.28, 0.76, 0.17, 0.96, 2.61, 3.10, 3.73, 0.37, 4.12, 2.37, 2.25, 0.19, 0.31, 3.61, 0.89, 1.96, 3.89, 0.86, 3.65, 1.63, 0.31, 2.27, 1.28, 0.66, 4.09, 4.18, 2.46, 2.88, 2.23\n",
      "    True sol: -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, 1, -0, 1, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, True obj: 24.00\n",
      "    Pred sol: 0, 0, -0, -0, 0, 0, 0, 0, -0, 0, 0, -0, -0, 0, 0, 0, 0, 0, 0, 1, -0, -0, -0, 0, 0, 1, 0, 1, 0, 0, -0, -0, 0, -0, 0, 1, -0, 1, -0, -0, 0, 0, -0, 0, 1, 0, 0, 0, Pred obj: 21.00\n",
      "\n",
      "Sample 6:\n",
      "    True cost: 11.00, 6.00, 4.00, 3.00, 10.00, 3.00, 14.00, 6.00, 7.00, 12.00, 4.00, 8.00, 6.00, 7.00, 2.00, 15.00, 11.00, 14.00, 1.00, 1.00, 5.00, 5.00, 7.00, 5.00, 5.00, 1.00, 11.00, 1.00, 4.00, 5.00, 6.00, 6.00, 3.00, 8.00, 3.00, 2.00, 3.00, 2.00, 2.00, 7.00, 11.00, 4.00, 10.00, 3.00, 1.00, 4.00, 8.00, 10.00\n",
      "    Pred cost: 11.16, 5.18, 9.49, 4.80, 11.04, 5.73, 8.22, 7.48, 6.38, 12.09, 6.01, 7.22, 7.11, 5.10, 2.69, 10.97, 8.99, 9.25, 0.83, -0.39, 7.34, 9.75, 7.80, 7.11, 3.09, 0.87, 9.71, 0.18, 6.50, 7.98, 8.94, 10.33, 4.73, 9.08, 3.59, 3.50, 8.54, 2.01, 3.02, 9.35, 7.98, 6.57, 7.03, 3.36, 0.90, 6.14, 5.53, 9.93\n",
      "    True sol: 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, 1, -0, -0, -0, -0, 1, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, True obj: 78.00\n",
      "    Pred sol: 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, Pred obj: 78.00\n",
      "\n",
      "Sample 7:\n",
      "    True cost: 7.00, 6.00, 3.00, 4.00, 2.00, 3.00, 3.00, 3.00, 3.00, 6.00, 4.00, 4.00, 5.00, 6.00, 4.00, 7.00, 4.00, 3.00, 2.00, 2.00, 4.00, 4.00, 5.00, 2.00, 2.00, 2.00, 8.00, 3.00, 3.00, 5.00, 4.00, 4.00, 5.00, 3.00, 5.00, 3.00, 5.00, 2.00, 3.00, 4.00, 4.00, 8.00, 6.00, 3.00, 2.00, 3.00, 3.00, 3.00\n",
      "    Pred cost: 8.31, 7.26, 6.75, 4.70, 5.47, 4.63, 4.00, 3.46, 4.86, 8.54, 6.83, 3.64, 5.50, 4.45, 3.19, 8.14, 4.66, 4.97, 4.74, 2.00, 5.11, 6.90, 5.41, 2.80, 3.15, 2.46, 7.03, 2.20, 2.80, 3.76, 6.43, 7.19, 4.29, 5.81, 5.98, 3.85, 5.94, 3.08, 4.96, 6.91, 3.70, 7.04, 5.49, 3.68, 2.07, 2.69, 4.48, 4.37\n",
      "    True sol: 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, 1, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, True obj: 44.00\n",
      "    Pred sol: 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, Pred obj: 44.00\n",
      "\n",
      "Sample 8:\n",
      "    True cost: 2.00, 3.00, 3.00, 3.00, 1.00, 3.00, 2.00, 2.00, 2.00, 3.00, 5.00, 2.00, 2.00, 2.00, 3.00, 5.00, 1.00, 2.00, 5.00, 2.00, 4.00, 1.00, 3.00, 2.00, 2.00, 2.00, 2.00, 2.00, 2.00, 4.00, 4.00, 2.00, 2.00, 1.00, 1.00, 1.00, 3.00, 2.00, 6.00, 1.00, 4.00, 2.00, 3.00, 2.00, 2.00, 4.00, 2.00, 1.00\n",
      "    Pred cost: 3.92, 5.04, 3.20, 3.56, 2.46, 3.79, 3.01, 3.58, 4.72, 4.14, 4.86, 3.88, 4.11, 2.79, 2.41, 5.68, 2.09, 2.17, 4.61, 1.38, 4.78, 3.68, 5.26, 2.28, 3.15, 1.89, 5.12, 1.41, 3.51, 3.85, 4.84, 3.59, 1.29, 2.96, 2.86, 1.03, 3.13, 1.96, 4.52, 3.52, 3.90, 4.76, 5.21, 0.91, 1.31, 3.63, 3.12, 1.81\n",
      "    True sol: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, True obj: 30.00\n",
      "    Pred sol: -0, 1, -0, -0, -0, -0, -0, -0, -0, 1, 1, -0, -0, -0, -0, 1, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, 0, -0, -0, -0, -0, -0, Pred obj: 27.00\n",
      "\n",
      "Sample 9:\n",
      "    True cost: 3.00, 11.00, 3.00, 1.00, 3.00, 1.00, 10.00, 1.00, 1.00, 2.00, 16.00, 1.00, 1.00, 8.00, 1.00, 5.00, 1.00, 2.00, 5.00, 2.00, 2.00, 2.00, 1.00, 1.00, 4.00, 1.00, 5.00, 1.00, 3.00, 2.00, 11.00, 2.00, 3.00, 2.00, 3.00, 5.00, 4.00, 1.00, 2.00, 2.00, 2.00, 11.00, 2.00, 6.00, 1.00, 3.00, 6.00, 2.00\n",
      "    Pred cost: 3.79, 9.29, 4.98, -1.37, 3.46, -1.35, 6.33, 1.62, 3.43, 4.77, 10.19, 1.30, -0.94, 8.85, 0.20, 8.03, 3.28, 2.77, 4.82, 0.68, 2.39, 5.24, 2.32, -0.50, 3.23, 1.27, 7.42, 0.58, 2.67, 2.27, 8.59, 4.54, 5.03, 4.85, 5.02, 6.91, 5.12, -0.17, 3.85, 4.86, 1.75, 9.71, 1.80, 6.26, 0.91, 1.36, 7.96, 4.77\n",
      "    True sol: 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, True obj: 62.00\n",
      "    Pred sol: -0, -0, -0, 0, -0, 0, -0, -0, -0, 1, 1, -0, 0, 1, -0, -0, -0, -0, -0, -0, -0, -0, -0, 0, -0, -0, 1, -0, -0, -0, -0, -0, -0, -0, -0, 1, -0, 0, -0, -0, -0, 1, -0, -0, -0, -0, 1, -0, Pred obj: 53.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare solutions\n",
    "for i, data in enumerate(ks_loader_test):\n",
    "    # load data\n",
    "    x, c, w, z = data\n",
    "    # cuda\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # convert to numpy\n",
    "    x = x.to(\"cpu\").detach().numpy()\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    # predict\n",
    "    cp = twostage_model.predict(x)\n",
    "    for j in range(min(10, batch_size)):\n",
    "        print(\"Sample {}:\".format(j))\n",
    "        print(\"    True cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in c[j]]))\n",
    "        print(\"    Pred cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in cp[j]]))\n",
    "        # solve cost from prediction\n",
    "        ks_model.setObj(cp[j])\n",
    "        wpj, _ = ks_model.solve()\n",
    "        zpj = np.dot(c[j], wpj)\n",
    "        print(\"    True sol: \" + \", \".join([\"{:.0f}\".format(x) for x in w[j]]) + \", True obj: {:.2f}\".format(z[j,0]))\n",
    "        print(\"    Pred sol: \"+  \", \".join([\"{:.0f}\".format(x) for x in wpj]) + \", Pred obj: {:.2f}\".format(zpj))\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f48395",
   "metadata": {},
   "source": [
    "## Two-Stage with Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8f42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33fb6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "twostage_model = pyepo.twostage.sklearnPred(Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00539d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat scorer\n",
    "spo_scorer = pyepo.metric.metrics.makeSkScorer(ks_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3be14571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build grid search\n",
    "grid = GridSearchCV(twostage_model, param_grid={\"estimator__alpha\": [0, 0.1, 0.5]}, scoring=spo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa578337",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.811213313339543 53.63112146156552\n",
      "14.81404529001557 49.0389940626865\n",
      "7.738298514213696 54.518821054032436\n",
      "6.988216231289783 101.73363764238334\n",
      "10.916063605339335 17.478800611644594\n",
      "6.143006506733492 41.94643695301857\n",
      "0.5939572692129325 26.024601616468097\n",
      "2.6289673942671925 36.803668803771586\n",
      "13.526973362568825 59.451332699121195\n",
      "5.0823850293451756 52.48870816923175\n",
      "2.985647514805315 55.67634785476104\n",
      "4.169356297881947 35.279090480994235\n",
      "4.6148105876175975 26.81479107650216\n",
      "4.576672623864276 45.56899067817178\n",
      "2.604371934182856 18.386510118281986\n",
      "5.724965228279004 37.72322852636093\n",
      "20.296760696300197 91.33642825094452\n",
      "1.9202590010584295 21.696421965623227\n",
      "7.8915124710011995 34.57717892232589\n",
      "16.050447556187336 105.6567119063525\n",
      "10.680960952406451 86.61061623849884\n",
      "10.766948734086142 70.54594288191171\n",
      "6.8098578827595375 48.554207201125536\n",
      "5.758296342172166 50.16013627747077\n",
      "1.7742934943522393 31.635506187902735\n",
      "3.844392207779279 40.691465462060606\n",
      "0.8390806553476189 20.46089295785512\n",
      "1.8879847500547662 27.316099364822616\n",
      "8.433162600883776 107.36821756766662\n",
      "7.24024752607022 47.685662240307906\n",
      "17.2754358554984 72.590656316365\n",
      "7.550299448501487 31.173738037354703\n",
      "2.101437835912165 39.04348899047389\n",
      "4.106644995149686 29.793074574321665\n",
      "5.019891916165307 51.03766882079232\n",
      "0.0 31.022707411560532\n",
      "0.0 48.38977357160239\n",
      "8.738745533864915 87.61744300305492\n",
      "10.736254592540703 74.54382603223524\n",
      "6.946677106081992 46.88333371352613\n",
      "15.759998529383907 57.75316541663077\n",
      "4.103813122418551 55.811973666655135\n",
      "4.186926464354961 57.00006198030018\n",
      "6.304217472164105 68.06500427721237\n",
      "3.8094500829586337 87.8278536254144\n",
      "2.806524238127409 85.94830700797425\n",
      "3.0592721808202548 29.795627022615008\n",
      "2.7392362578708394 33.326920628710084\n",
      "9.965419756560841 71.29281482016437\n",
      "7.5216698036062155 66.83046080276753\n",
      "1.5489646655043003 54.19053379340845\n",
      "5.741858281463642 43.79118424346938\n",
      "6.100937229901788 66.28670224865776\n",
      "3.171349993094907 48.117815929565005\n",
      "1.2943455430698023 34.24103220510865\n",
      "1.7521111938556082 32.01542219084146\n",
      "1.5971085198556736 25.348516345247226\n",
      "2.6781555848673406 26.23460792282799\n",
      "5.478707208298289 107.41341964891767\n",
      "12.872911130524201 13.315753519528677\n",
      "13.144874935437628 73.27852110900812\n",
      "12.786832298266958 91.0459137360613\n",
      "0.8866709313358854 48.03513242199489\n",
      "1.7425783146912046 31.918418431253084\n",
      "12.062994372844251 51.085884895964845\n",
      "3.820793229072727 37.61931504190272\n",
      "12.058823963663777 46.06267981379809\n",
      "14.247960434679207 74.15309066794237\n",
      "0.01502318386816981 28.95943061259326\n",
      "5.873415229383411 52.327410573142515\n",
      "4.619341263414725 43.92373972524165\n",
      "4.047351588146949 23.904379143852125\n",
      "0.06590124638230321 30.010368464814206\n",
      "15.348218275095391 93.32849629127395\n",
      "3.9248773802810533 48.1017180540861\n",
      "9.962660066358218 58.62980575614547\n",
      "7.868902351614409 43.755810316518605\n",
      "1.0171300048282603 81.30441384726305\n",
      "3.9608087046621137 77.17609479266189\n",
      "1.94947764357034 52.44005473473255\n",
      "6.138921223882171 45.19889583596151\n",
      "1.6052137389255847 43.79291507203274\n",
      "7.524325765692186 26.22833357369574\n",
      "1.4919990608842681 106.35071984393338\n",
      "5.14569515164375 41.599352981635825\n",
      "3.6521934118377004 62.1449217507385\n",
      "5.5868374461683885 72.4006810154666\n",
      "9.975313887278531 59.6588794956082\n",
      "10.04688775635045 42.37514470361782\n",
      "3.552713678800501e-15 31.165333970358216\n",
      "3.9725195297676947 38.20437361453432\n",
      "4.132207805582766 52.82195587543318\n",
      "8.087160631915921 74.08008655213354\n",
      "3.757868751975664 32.0770169161237\n",
      "1.0823377015610482 19.2759192375945\n",
      "1.1023058607844902 36.645200722450035\n",
      "3.079913161603045 36.76352267190229\n",
      "12.093925330799166 61.36568318997893\n",
      "3.1372090097787293 29.522187960939547\n",
      "4.224408158585433 50.326759083631956\n",
      "7.809166876311906 53.60035786701161\n",
      "14.809010781873418 49.01900250484731\n",
      "7.738043420144621 54.49853271948176\n",
      "6.976511988290156 101.64541586000632\n",
      "10.89621271604247 17.487444723128412\n",
      "6.147341945041028 41.946248703936995\n",
      "0.5943803383091257 26.022395447268078\n",
      "2.6253300259863366 36.78647112832979\n",
      "13.521495706795037 59.422522344093366\n",
      "5.078207446678533 52.46641883060224\n",
      "2.988151493535078 55.654246296763745\n",
      "4.159991023771411 35.27532527193955\n",
      "4.612254906550376 26.82179474233415\n",
      "4.569338686739613 45.542973381897056\n",
      "2.6016904453540004 18.392868558821302\n",
      "5.725256895756239 37.71427780301797\n",
      "20.274772297667838 91.25957947597732\n",
      "1.9196757701680731 21.704334632787887\n",
      "7.875806736788007 34.57035383303631\n",
      "16.040302667045538 105.5798861281008\n",
      "10.672479848256899 86.54251448518968\n",
      "10.766150266713645 70.51671048512966\n",
      "6.803604860505928 48.51583154291665\n",
      "5.760032998627935 50.14650426305684\n",
      "1.7696957811496077 31.61978580020607\n",
      "3.8459631348690024 40.67529362880045\n",
      "0.8372867633399999 20.461786201653858\n",
      "1.8875220125978238 27.318222594501133\n",
      "8.426397972812467 107.28056059838232\n",
      "7.234370600517721 47.657201064618334\n",
      "17.25353560996924 72.53226145289551\n",
      "7.545718495323197 31.162701119425954\n",
      "2.1000229629090583 39.0328648861342\n",
      "4.100189536107955 29.78341904919231\n",
      "5.013979901760422 51.00705517253189\n",
      "0.0 31.01570484094837\n",
      "-7.105427357601002e-15 48.36764889236031\n",
      "8.732655548788372 87.5655060929365\n",
      "10.734327677898612 74.51017419915254\n",
      "6.941388186018642 46.84986536654043\n",
      "15.747685624538747 57.71703935979814\n",
      "4.105805775605347 55.77303813819818\n",
      "4.179574276955272 56.95574057965576\n",
      "6.2984316857290565 68.0242088216368\n",
      "3.8024638867796625 87.76610466800076\n",
      "2.8074327726354937 85.88739216773223\n",
      "3.064199255198016 29.80115951284404\n",
      "2.7353100913998354 33.3181198848686\n",
      "9.959277612347414 71.23317962546375\n",
      "7.516454681345564 66.79217422114264\n",
      "1.5466877908445653 54.149084183071174\n",
      "5.739972937286261 43.77902547204106\n",
      "6.09776350823622 66.24855135053696\n",
      "3.16688881235077 48.095034186813905\n",
      "1.3009934201989708 34.237480237290576\n",
      "1.7503512941593051 32.010183846546155\n",
      "1.593790235505562 25.342336054366744\n",
      "2.679820711280886 26.235533568224106\n",
      "5.474367352314417 107.32530428876782\n",
      "12.849427652103138 13.320942206150987\n",
      "13.136726122015816 73.22456995716641\n",
      "12.776244585584934 90.96667554845374\n",
      "0.8860613796815642 48.011550874940795\n",
      "1.74355108224999 31.920240481293543\n",
      "12.054482524986952 51.05858113848925\n",
      "3.8225281064633236 37.61301716605488\n",
      "12.058006577826305 46.04696471343327\n",
      "14.234566012245452 74.09961483043632\n",
      "0.01527294463723905 28.95937230686809\n",
      "5.870406400258879 52.29324975403157\n",
      "4.61377789437573 43.91214442427342\n",
      "4.046550552014988 23.90527257964717\n",
      "0.06364198869720283 30.012281825946765\n",
      "15.33896726149095 93.27413381460198\n",
      "3.9237396184455946 48.0914335071614\n",
      "9.954899666997534 58.60384311874739\n",
      "7.871421536676763 43.75126913383362\n",
      "1.016149116714658 81.25366330143117\n",
      "3.9601230276904573 77.13784627525487\n",
      "1.9511751508139312 52.41710376636043\n",
      "6.137495083118644 45.183334150201205\n",
      "1.6041046742815013 43.77198829799137\n",
      "7.520095210609082 26.2290351295002\n",
      "1.4900401565304406 106.24440203272545\n",
      "5.144954323356409 41.588908196196726\n",
      "3.6472245143281086 62.09529438056172\n",
      "5.580549713870823 72.35047902035546\n",
      "9.9623545825051 59.62391504324989\n",
      "10.044669945833235 42.355512691493566\n",
      "0.0 31.150292904211604\n",
      "3.974438683819308 38.183522113520745\n",
      "4.133437820613132 52.79233136303154\n",
      "8.082297754306637 74.01901691057378\n",
      "3.751583311275702 32.06764584267511\n",
      "1.0804511240017867 19.28327784829372\n",
      "1.1016252348004087 36.63061767603731\n",
      "3.069945957333502 36.74825721502982\n",
      "12.086021243856834 61.32717011136501\n",
      "3.1345081730915396 29.51294874563309\n",
      "4.223548101163466 50.287982237516935\n",
      "7.801147546650611 53.47834385676994\n",
      "14.788990447280142 48.939486562011055\n",
      "7.73695954863004 54.417690832146995\n",
      "6.930119953742562 101.29495637286689\n",
      "10.817286585824638 17.521735493178074\n",
      "6.164426075485345 41.9452657017448\n",
      "0.5960708731302766 26.013669500525936\n",
      "2.6108944102506797 36.71829981777431\n",
      "13.499735327274223 59.308012240101\n",
      "5.0616267235753085 52.377863342929295\n",
      "2.9980526879410476 55.56630257094382\n",
      "4.122717165942426 35.26018493721604\n",
      "4.602162757072467 26.84959090798889\n",
      "4.540283415289657 45.43994916207239\n",
      "2.5910306818745923 18.41813985967903\n",
      "5.726399526099442 37.678694099839\n",
      "20.187588088131918 90.95453959567621\n",
      "1.917366446658118 21.735816203570597\n",
      "7.813602867579455 34.54327260913594\n",
      "15.99991667238767 105.27421299643356\n",
      "10.638800417890863 86.27201439891002\n",
      "10.762879767798097 70.40017418244315\n",
      "6.778939542192468 48.36396046158611\n",
      "5.766820517348862 50.09217600819612\n",
      "1.75147769963543 31.55755472661117\n",
      "3.8522160902039033 40.61112692558518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8301871987980647 20.465434984768848\n",
      "1.8857059303657024 27.326709103932544\n",
      "8.399486550340953 106.932146691312\n",
      "7.211128059832774 47.544424757395035\n",
      "17.1667837411156 72.30065949207963\n",
      "7.527755751129838 31.119259271508547\n",
      "2.094445886925051 38.99071519384683\n",
      "4.074670088536319 29.745381727490578\n",
      "4.9905277431267905 50.88563137469147\n",
      "0.0 30.98785444353971\n",
      "1.4210854715202004e-14 48.279738825200326\n",
      "8.70840697280289 87.35877863572892\n",
      "10.726575661563828 74.37611281765287\n",
      "6.9204873400253035 46.71742310628157\n",
      "15.69884313171032 57.57368970738736\n",
      "4.113755738956229 55.61851701269242\n",
      "4.150381288143848 56.77970059144752\n",
      "6.275478389946485 67.86199230977196\n",
      "3.774756547221415 87.52059285339331\n",
      "2.8109604512828668 85.64522326902362\n",
      "3.0837359003146965 29.82303427814308\n",
      "2.7197103975237376 33.28307615317825\n",
      "9.934884031287936 70.99641598858015\n",
      "7.49570296877981 66.63991271907909\n",
      "1.5376385019907843 53.984414574243885\n",
      "5.7324562527521294 43.73058371878227\n",
      "6.085146899851246 66.09684572358847\n",
      "3.1491893810298706 48.004401640354146\n",
      "1.3273698746844644 34.223317763424404\n",
      "1.7433608637829714 31.989306520297085\n",
      "1.5806355881187244 25.317891441822646\n",
      "2.686456750533054 26.23926254947198\n",
      "5.457072988864837 106.97496566535605\n",
      "12.75606149877309 13.341583267240543\n",
      "13.104336496602983 73.01034594951963\n",
      "12.734210998403725 90.65200709725961\n",
      "0.8837123068396266 47.91792579876301\n",
      "1.7474203494445817 31.92747081504271\n",
      "12.020699067453513 50.95019901395817\n",
      "3.8294469351731237 37.58799636764054\n",
      "12.054679329710169 45.9844756057318\n",
      "14.18143731561161 73.88723205863579\n",
      "0.0162700850678128 28.95915063096525\n",
      "5.858455308468869 52.15759563353429\n",
      "4.591633379699495 43.865964633619654\n",
      "4.0433973187859245 23.908890351639833\n",
      "0.054675535040686896 30.019823061769745\n",
      "15.302137779791082 93.05766838241408\n",
      "3.919245385882938 48.05037492944932\n",
      "9.924062163769435 58.50057516254489\n",
      "7.881330535145004 43.73304742594937\n",
      "1.0122780616637783 81.05188705575584\n",
      "3.9573696511705805 76.98545623575181\n",
      "1.9578898858187728 52.32576161132258\n",
      "6.1319159299471195 45.12158321472423\n",
      "1.599733332801101 43.6889321397861\n",
      "7.503321985382584 26.231885901545887\n",
      "1.4822295097678904 105.82252016065468\n",
      "5.14200986682247 41.54738961484544\n",
      "3.62751587378731 61.89820948048672\n",
      "5.555606429581417 72.151201430615\n",
      "9.910942574242739 59.48499763717619\n",
      "10.035948425422362 42.27779018268172\n",
      "0.0 31.090742958504705\n",
      "3.9820811265625906 38.1009532994122\n",
      "4.138299124590503 52.67472985968104\n",
      "8.062954941242154 73.7764640478487\n",
      "3.7266545369876063 32.03043199056661\n",
      "1.0729999861647457 19.312617996033232\n",
      "1.0989351573807582 36.57261869131579\n",
      "3.030367628965408 36.68766074146737\n",
      "12.054611724883365 61.17422456898122\n",
      "3.1238228917555624 29.476374016273727\n",
      "4.220285100308793 50.13441857172967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputRegressor(estimator=Ridge()),\n",
       "             param_grid={'estimator__alpha': [0, 0.1, 0.5]},\n",
       "             scoring=make_scorer(SPOError, greater_is_better=False, model_type=<class 'pyepo.model.grb.knapsack.knapsackModel'>, args={'weights': array([[4.59, 4.87, 5.19, 7.59, 6.8 , 4.97, 4.84, 3.22, 7.9 , 3.62, 3.12,\n",
       "        6.81, 7.09, 3.23, 4.47, 5.23, 6.11, 5.23, 4.27, 6.66, 5.21, 3.72,\n",
       "        7.83, 5.64, 7.56, 3.28, 4.31, 3.85, 6.43, 4.26, 7.56, 6.4 , 6.09,\n",
       "        6.4 , 4.5 , 6.31, 6.35, 3.07, 6.03, 7.39, 3.48, 5.57, 6.27, 4.55,\n",
       "        5.64, 5.66, 3.27, 6.68],\n",
       "       [4.2 , 5.61, 6.13, 7.88, 4.61, 4.92, 6.09, 7.95, 7.11, 4.02, 3.07,\n",
       "        7.84, 6.29, 5.78, 5.57, 5.65, 7.41, 5.21, 3.42, 6.48, 5.77, 7.67,\n",
       "        7.32, 3.31, 4.36, 4.75, 3.38, 3.44, 6.3 , 4.85, 7.09, 5.7 , 4.05,\n",
       "        6.04, 6.51, 3.41, 7.94, 6.05, 7.18, 3.64, 4.35, 4.45, 4.27, 4.87,\n",
       "        5.74, 3.16, 5.41, 3.81]]), 'capacity': array([30, 30])}))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "grid.fit(ks_dataset_train.feats, ks_dataset_train.costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f735d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "c_test_pred = grid.predict(ks_dataset_test.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████████████▍        | 910/1000 [00:22<00:02, 33.44it/s]"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "truespo = 0\n",
    "unambspo = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    c_pred_i = c_test_pred[i]\n",
    "    c_true_i = ks_dataset_test.costs[i]\n",
    "    z_true_i = ks_dataset_test.objs[i,0]\n",
    "    truespo += pyepo.metric.calRegret(ks_model, c_pred_i, c_true_i, z_true_i)\n",
    "    unambspo += pyepo.metric.calUnambRegret(ks_model, c_pred_i, c_true_i, z_true_i)\n",
    "time.sleep(1)\n",
    "print(\"Normalized true SPO Loss: {:.2f}%\".format(truespo / abs(ks_dataset_test.objs.sum()) * 100))\n",
    "print(\"Normalized unambiguous SPO Loss: {:.2f}%\".format(unambspo / abs(ks_dataset_test.objs.sum()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa9d5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare solutions\n",
    "for i, data in enumerate(ks_loader_test):\n",
    "    # load data\n",
    "    x, c, w, z = data\n",
    "    # cuda\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # convert to numpy\n",
    "    x = x.to(\"cpu\").detach().numpy()\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    # predict\n",
    "    cp = grid.predict(x)\n",
    "    for j in range(min(10, batch_size)):\n",
    "        print(\"Sample {}:\".format(j))\n",
    "        print(\"    True cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in c[j]]))\n",
    "        print(\"    Pred cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in cp[j]]))\n",
    "        # solve cost from prediction\n",
    "        ks_model.setObj(cp[j])\n",
    "        wpj, _ = ks_model.solve()\n",
    "        zpj = np.dot(c[j], wpj)\n",
    "        print(\"    True sol: \" + \", \".join([\"{:.0f}\".format(x) for x in w[j]]) + \", True obj: {:.2f}\".format(z[j,0]))\n",
    "        print(\"    Pred sol: \"+  \", \".join([\"{:.0f}\".format(x) for x in wpj]) + \", Pred obj: {:.2f}\".format(zpj))\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596e709",
   "metadata": {},
   "source": [
    "## Linear Regression from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed32466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(p, m)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f22f2",
   "metadata": {},
   "source": [
    "## SPO+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07753d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    reg = reg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init SPO+ loss\n",
    "criterion = pyepo.func.SPOPlus(ks_model, processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05c841",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "num_epochs = 300\n",
    "reg.train()\n",
    "loss_log = []\n",
    "loss_log_truespo = []\n",
    "loss_log_unambspo = []\n",
    "for epoch in range(num_epochs):\n",
    "    # load data\n",
    "    for i, data in enumerate(ks_loader_train):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = reg(x)\n",
    "        loss = criterion.apply(cp, c, w, z).mean()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_log.append(loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # true SPO\n",
    "        trueloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_truespo.append(trueloss)\n",
    "        # unambiguous SPO \n",
    "        unambloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_unambspo.append(unambloss)\n",
    "        print(\"Epoch {:3}, Loss: {:8.4f}, True SPO Loss: {:7.4f}%, Unambiguous SPO Loss: {:7.4f}%\". \\\n",
    "              format(epoch+1, loss.item(), trueloss*100, unambloss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bf5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(loss_log, color=\"c\", lw=3)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae91bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_truespo, color=\"b\", alpha=0.5, lw=3, label=\"Regret\")\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_unambspo, color=\"y\", alpha=0.5, lw=3, label=\"Unambiguous Regret\")\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8515a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "spoloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized true SPO Loss: {:.2f}%\".format(spoloss * 100))\n",
    "spoloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized unambiguous SPO Loss: {:.2f}%\".format(spoloss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c1d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg.eval()\n",
    "# compare solutions\n",
    "for i, data in enumerate(ks_loader_test):\n",
    "    # load data\n",
    "    x, c, w, z = data\n",
    "    # cuda\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # convert to numpy\n",
    "    x = x.to(\"cpu\").detach().numpy()\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    cp = cp.to(\"cpu\").detach().numpy()\n",
    "    for j in range(min(10, batch_size)):\n",
    "        print(\"Sample {}:\".format(j))\n",
    "        print(\"    True cost:\", \", \".join([\"{:.2f}\".format(-cost) for cost in c[j]]))\n",
    "        print(\"    Pred cost:\", \", \".join([\"{:.2f}\".format(-cost) for cost in cp[j]]))\n",
    "        # solve cost from prediction\n",
    "        ks_model.setObj(cp[j])\n",
    "        wpj, _ = ks_model.solve()\n",
    "        zpj = np.dot(c[j], wpj)\n",
    "        print(\"    True sol: \" + \", \".join([\"{:.0f}\".format(x) for x in w[j]]) + \", True obj: {:.2f}\".format(-z[j,0]))\n",
    "        print(\"    Pred sol: \"+  \", \".join([\"{:.0f}\".format(x) for x in wpj]) + \", Pred obj: {:.2f}\".format(-zpj))\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df20405",
   "metadata": {},
   "source": [
    "## SPO+ Rel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71994d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    reg = reg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1840354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init SPO+ loss\n",
    "criterion = pyepo.func.SPOPlus(ks_model_rel, processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "num_epochs = 300\n",
    "reg.train()\n",
    "loss_log = []\n",
    "loss_log_truespo = []\n",
    "loss_log_unambspo = []\n",
    "for epoch in range(num_epochs):\n",
    "    # load data\n",
    "    for i, data in enumerate(ks_loader_train_rel):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = reg(x)\n",
    "        loss = criterion.apply(cp, c, w, z).mean()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_log.append(loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # true SPO\n",
    "        trueloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_truespo.append(trueloss)\n",
    "        # unambiguous SPO \n",
    "        unambloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_unambspo.append(unambloss)\n",
    "        print(\"Epoch {:3}, Loss: {:8.4f}, True SPO Loss: {:7.4f}%, Unambiguous SPO Loss: {:7.4f}%\". \\\n",
    "              format(epoch+1, loss.item(), trueloss*100, unambloss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(loss_log, color=\"c\", lw=3)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_truespo, color=\"b\", alpha=0.5, lw=3, label=\"Regret\")\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_unambspo, color=\"y\", alpha=0.5, lw=3, label=\"Unambiguous Regret\")\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "spoloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized true SPO Loss: {:.2f}%\".format(spoloss * 100))\n",
    "spoloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized unambiguous SPO Loss: {:.2f}%\".format(spoloss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd188e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg.eval()\n",
    "# compare solutions\n",
    "for i, data in enumerate(ks_loader_test):\n",
    "    # load data\n",
    "    x, c, w, z = data\n",
    "    # cuda\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # convert to numpy\n",
    "    x = x.to(\"cpu\").detach().numpy()\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    cp = cp.to(\"cpu\").detach().numpy()\n",
    "    for j in range(min(10, batch_size)):\n",
    "        print(\"Sample {}:\".format(j))\n",
    "        print(\"    True cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in c[j]]))\n",
    "        print(\"    Pred cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in cp[j]]))\n",
    "        # solve cost from prediction\n",
    "        ks_model.setObj(cp[j])\n",
    "        wpj, _ = ks_model.solve()\n",
    "        zpj = np.dot(c[j], wpj)\n",
    "        print(\"    True sol: \" + \", \".join([\"{:.0f}\".format(x) for x in w[j]]) + \", True obj: {:.2f}\".format(z[j,0]))\n",
    "        print(\"    Pred sol: \"+  \", \".join([\"{:.0f}\".format(x) for x in wpj]) + \", Pred obj: {:.2f}\".format(zpj))\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96fcde",
   "metadata": {},
   "source": [
    "## Black-Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383005aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    reg = reg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b534a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss\n",
    "bb = pyepo.func.blackboxOpt(ks_model, lambd=20, processes=4)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "num_epochs = 300\n",
    "reg.train()\n",
    "loss_log = []\n",
    "loss_log_truespo = []\n",
    "loss_log_unambspo = []\n",
    "for epoch in range(num_epochs):\n",
    "    # load data\n",
    "    for i, data in enumerate(ks_loader_train):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # linear regression\n",
    "        cp = reg(x)\n",
    "        # black-box optimizer\n",
    "        wp = bb.apply(cp)\n",
    "        # objective value\n",
    "        zp = (wp * c).sum(1).view(-1, 1)\n",
    "        # loss\n",
    "        loss = criterion(zp, z)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_log.append(loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # true SPO\n",
    "        trueloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_truespo.append(trueloss)\n",
    "        # unambiguous SPO \n",
    "        unambloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "        loss_log_unambspo.append(unambloss)\n",
    "        print(\"Epoch {:3}, Loss: {:8.4f}, True SPO Loss: {:7.4f}%, Unambiguous SPO Loss: {:7.4f}%\". \\\n",
    "              format(epoch+1, loss.item(), trueloss*100, unambloss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb79450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(loss_log, color=\"c\", lw=3)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e634d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_truespo, color=\"b\", alpha=0.5, lw=3, label=\"Regret\")\n",
    "plt.plot(range(0, num_epochs, 10), loss_log_unambspo, color=\"y\", alpha=0.5, lw=3, label=\"Unambiguous Regret\")\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "spoloss = pyepo.metric.regret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized true SPO Loss: {:.2f}%\".format(spoloss * 100))\n",
    "spoloss = pyepo.metric.unambRegret(reg, ks_model, ks_loader_test)\n",
    "print(\"Normalized unambiguous SPO Loss: {:.2f}%\".format(spoloss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b44a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg.eval()\n",
    "# compare solutions\n",
    "for i, data in enumerate(ks_loader_test):\n",
    "    # load data\n",
    "    x, c, w, z = data\n",
    "    # cuda\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # convert to numpy\n",
    "    x = x.to(\"cpu\").detach().numpy()\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    cp = cp.to(\"cpu\").detach().numpy()\n",
    "    for j in range(min(10, batch_size)):\n",
    "        print(\"Sample {}:\".format(j))\n",
    "        print(\"    True cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in c[j]]))\n",
    "        print(\"    Pred cost:\", \", \".join([\"{:.2f}\".format(cost) for cost in cp[j]]))\n",
    "        # solve cost from prediction\n",
    "        ks_model.setObj(cp[j])\n",
    "        wpj, _ = ks_model.solve()\n",
    "        zpj = np.dot(c[j], wpj)\n",
    "        print(\"    True sol: \" + \", \".join([\"{:.0f}\".format(x) for x in w[j]]) + \", True obj: {:.2f}\".format(z[j,0]))\n",
    "        print(\"    Pred sol: \"+  \", \".join([\"{:.0f}\".format(x) for x in wpj]) + \", Pred obj: {:.2f}\".format(zpj))\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a2b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
