{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf912cf8",
   "metadata": {},
   "source": [
    "# Warcraft Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set work dir\n",
    "import os\n",
    "os.chdir(\"../pkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pyepo\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# fix random seed\n",
    "random.seed(135)\n",
    "np.random.seed(135)\n",
    "torch.manual_seed(135)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b83a43",
   "metadata": {},
   "source": [
    "## 1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d022200",
   "metadata": {},
   "source": [
    "We use the Warcraft terrains shortest paths [dateset](https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.YJCQ5S). Datasets were randomly generated from the Warcraft II [tileset](http://github.com/war2/war2edit) and used in Vlastelica, Marin, et al. \"Differentiation of Blackbox Combinatorial Solvers\". The Warcraft dataset is a captivating benchmark because the image input feature allows learning the shortest path from 10000 RGB terrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4791e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map size\n",
    "k = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8353b0",
   "metadata": {},
   "source": [
    "### 1.1 Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmaps_train = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/train_maps.npy\".format(k,k))\n",
    "#tmaps_val = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/val_maps.npy\".format(k,k))\n",
    "tmaps_test = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/test_maps.npy\".format(k,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(tmaps_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903781d",
   "metadata": {},
   "source": [
    "### 1.2 Costs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_train = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/train_vertex_weights.npy\".format(k,k))\n",
    "#costs_val = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/val_vertex_weights.npy\".format(k,k))\n",
    "costs_test = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/test_vertex_weights.npy\".format(k,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(costs_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723276c",
   "metadata": {},
   "source": [
    "### 1.3 Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87438df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_train = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/train_shortest_paths.npy\".format(k,k))\n",
    "#paths_val = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/val_shortest_paths.npy\".format(k,k))\n",
    "paths_test = np.load(\"../data/warcraft_shortest_path_oneskin/{}x{}/test_shortest_paths.npy\".format(k,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a03f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(paths_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83d132",
   "metadata": {},
   "source": [
    "## 2 Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class mapDataset(Dataset):\n",
    "    def __init__(self, tmaps, costs, paths):\n",
    "        self.tmaps = tmaps\n",
    "        self.costs = costs\n",
    "        self.paths = paths\n",
    "        self.objs = (costs * paths).sum(axis=(1,2)).reshape(-1,1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.costs)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        return (\n",
    "            torch.FloatTensor(self.tmaps[ind].transpose(2, 0, 1)/255).detach(), # image\n",
    "            torch.FloatTensor(self.costs[ind]).reshape(-1),\n",
    "            torch.FloatTensor(self.paths[ind]).reshape(-1),\n",
    "            torch.FloatTensor(self.objs[ind]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "dataset_train = mapDataset(tmaps_train, costs_train, paths_train)\n",
    "#dataset_val = mapDataset(tmaps_val, costs_val, paths_val)\n",
    "dataset_test = mapDataset(tmaps_test, costs_test, paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 70\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "#loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190c011",
   "metadata": {},
   "source": [
    "## 3 Neural Network: Truncated Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ec3ec",
   "metadata": {},
   "source": [
    "Same as previous paper, we used the truncated ResNet18 (first five layers), $50$ epochs with batches of size $70$, learning rate $0.0005$ decaying at the epochs $30$ and $40$, and $n = 1, \\sigma = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca2e1d",
   "metadata": {},
   "source": [
    "### 3.1 Orignal Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "nnet = resnet18(pretrained=False)\n",
    "print(nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa5e75",
   "metadata": {},
   "source": [
    "### 3.2 Truncated Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77008efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build new ResNet18 with Max Pooling\n",
    "class partialResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        super(partialResNet, self).__init__()\n",
    "        # init resnet 18\n",
    "        resnet = resnet18(pretrained=False)\n",
    "        # first five layers of ResNet18\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool1 = resnet.maxpool\n",
    "        self.block = resnet.layer1\n",
    "        # conv to 1 channel\n",
    "        self.conv2  = nn.Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        # max pooling\n",
    "        self.maxpool2 = nn.AdaptiveMaxPool2d((k,k))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bn(h)\n",
    "        h = self.relu(h)\n",
    "        h = self.maxpool1(h)\n",
    "        h = self.block(h)\n",
    "        h = self.conv2(h)\n",
    "        out = self.maxpool2(h)\n",
    "        # reshape for optmodel\n",
    "        out = torch.squeeze(out, 1)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee41336",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60971dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "epochs = 50\n",
    "# learning rate\n",
    "lr = 5e-4\n",
    "# log step\n",
    "log_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf12ea4",
   "metadata": {},
   "source": [
    "## 4 Optimization Model: Linear Programming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d187f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from pyepo.model.grb.grbmodel import optGrbModel\n",
    "\n",
    "class shortestPathModel(optGrbModel):\n",
    "    \"\"\"\n",
    "    This class is optimization model for shortest path problem on 2D grid with 8 neighbors\n",
    "\n",
    "    Attributes:\n",
    "        _model (GurobiPy model): Gurobi model\n",
    "        grid (tuple of int): Size of grid network\n",
    "        nodes (list): list of vertex\n",
    "        edges (list): List of arcs\n",
    "        nodes_map (ndarray): 2D array for node index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            grid (tuple of int): size of grid network\n",
    "        \"\"\"\n",
    "        self.grid = grid\n",
    "        self.nodes, self.edges, self.nodes_map = self._getEdges()\n",
    "        super().__init__()\n",
    "\n",
    "    def _getEdges(self):\n",
    "        \"\"\"\n",
    "        A method to get list of edges for grid network\n",
    "\n",
    "        Returns:\n",
    "            list: arcs\n",
    "        \"\"\"\n",
    "        # init list\n",
    "        nodes, edges = [], []\n",
    "        # init map from coord to ind\n",
    "        nodes_map = {}\n",
    "        for i in range(self.grid[0]):\n",
    "            for j in range(self.grid[1]):\n",
    "                u = self._calNode(i, j)\n",
    "                nodes_map[u] = (i,j)\n",
    "                nodes.append(u)\n",
    "                # edge to 8 neighbors\n",
    "                # up\n",
    "                if i != 0:\n",
    "                    v = self._calNode(i-1, j)\n",
    "                    edges.append((u,v))\n",
    "                    # up-right\n",
    "                    if j != self.grid[1] - 1:\n",
    "                        v = self._calNode(i-1, j+1)\n",
    "                        edges.append((u,v))\n",
    "                # right\n",
    "                if j != self.grid[1] - 1:\n",
    "                    v = self._calNode(i, j+1)\n",
    "                    edges.append((u,v))\n",
    "                    # down-right\n",
    "                    if i != self.grid[0] - 1:\n",
    "                        v = self._calNode(i+1, j+1)\n",
    "                        edges.append((u,v))\n",
    "                # down\n",
    "                if i != self.grid[0] - 1:\n",
    "                    v = self._calNode(i+1, j)\n",
    "                    edges.append((u,v))\n",
    "                    # down-left\n",
    "                    if j != 0:\n",
    "                        v = self._calNode(i+1, j-1)\n",
    "                        edges.append((u,v))\n",
    "                # left\n",
    "                if j != 0:\n",
    "                    v = self._calNode(i, j-1)\n",
    "                    edges.append((u,v))\n",
    "                    # top-left\n",
    "                    if i != 0:\n",
    "                        v = self._calNode(i-1, j-1)\n",
    "                        edges.append((u,v))\n",
    "        return nodes, edges, nodes_map\n",
    "    \n",
    "    def _calNode(self, x, y):\n",
    "        \"\"\"\n",
    "        A method to calculate index of node\n",
    "        \"\"\"\n",
    "        v = x * self.grid[1] + y\n",
    "        return v\n",
    "\n",
    "    def _getModel(self):\n",
    "        \"\"\"\n",
    "        A method to build Gurobi model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimization model and variables\n",
    "        \"\"\"\n",
    "        # ceate a model\n",
    "        m = gp.Model(\"shortest path\")\n",
    "        # varibles\n",
    "        x = m.addVars(self.edges, ub=1, name=\"x\")\n",
    "        # sense\n",
    "        m.modelSense = GRB.MINIMIZE\n",
    "        # constraints\n",
    "        for i in range(self.grid[0]):\n",
    "            for j in range(self.grid[1]):\n",
    "                v = self._calNode(i, j)\n",
    "                expr = 0\n",
    "                for e in self.edges:\n",
    "                    # flow in\n",
    "                    if v == e[1]:\n",
    "                        expr += x[e]\n",
    "                    # flow out\n",
    "                    elif v == e[0]:\n",
    "                        expr -= x[e]\n",
    "                # source\n",
    "                if i == 0 and j == 0:\n",
    "                    m.addConstr(expr == -1)\n",
    "                # sink\n",
    "                elif i == self.grid[0] - 1 and j == self.grid[0] - 1:\n",
    "                    m.addConstr(expr == 1)\n",
    "                # transition\n",
    "                else:\n",
    "                    m.addConstr(expr == 0)\n",
    "        return m, x\n",
    "    \n",
    "    def setObj(self, c):\n",
    "        \"\"\"\n",
    "        A method to set objective function\n",
    "\n",
    "        Args:\n",
    "            c (np.ndarray): cost of objective function\n",
    "        \"\"\"\n",
    "        # vector to matrix\n",
    "        c = c.reshape(self.grid)\n",
    "        # sum up vector cost\n",
    "        obj = c[0,0] + gp.quicksum(c[self.nodes_map[j]] * self.x[i,j] for i, j in self.x)\n",
    "        self._model.setObjective(obj)\n",
    "        \n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "        A method to solve model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimal solution (list) and objective value (float)\n",
    "        \"\"\"\n",
    "        # update gurobi model\n",
    "        self._model.update()\n",
    "        # solve\n",
    "        self._model.optimize()\n",
    "        # kxk solution map\n",
    "        sol = np.zeros(self.grid)\n",
    "        for i, j in self.edges:\n",
    "            # active edge\n",
    "            if abs(1 - self.x[i,j].x) < 1e-3:\n",
    "                # node on active edge\n",
    "                sol[self.nodes_map[i]] = 1\n",
    "                sol[self.nodes_map[j]] = 1\n",
    "        # matrix to vector\n",
    "        sol = sol.reshape(-1)\n",
    "        return sol, self._model.objVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b685b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "grid = (k, k)\n",
    "optmodel = shortestPathModel(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb15e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "optmodel.setObj(costs_train[0]) # assign cost\n",
    "sol, obj = optmodel.solve() # solve\n",
    "print(\"Obj: {}\".format(obj))\n",
    "print(\"Path:\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(sol.reshape(k,k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6fee6",
   "metadata": {},
   "source": [
    "## 5 Useful Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class earlyStopper:\n",
    "    \"\"\"\n",
    "    Early stopping for training\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.min_regret = np.inf\n",
    "\n",
    "    def stop(self, regret):\n",
    "        if regret + 1e-5 < self.min_regret:\n",
    "            self.min_regret = regret\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f668ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(nnet, optmodel, dataloader):\n",
    "    # init data\n",
    "    data = {\"Regret\":[], \"Relative Regret\":[], \"Accuracy\":[], \"Optimal\":[]}\n",
    "    # eval\n",
    "    nnet.eval()\n",
    "    for x, c, w, z in tqdm(dataloader):\n",
    "        # cuda\n",
    "        if next(nnet.parameters()).is_cuda:\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # predict\n",
    "        cp = nnet(x)\n",
    "        # to numpy\n",
    "        c = c.to(\"cpu\").detach().numpy()\n",
    "        w = w.to(\"cpu\").detach().numpy()\n",
    "        z = z.to(\"cpu\").detach().numpy()\n",
    "        cp = cp.to(\"cpu\").detach().numpy()\n",
    "        # solve\n",
    "        for i in range(cp.shape[0]):\n",
    "            # sol for pred cost\n",
    "            optmodel.setObj(cp[i])\n",
    "            wpi, _ = optmodel.solve()\n",
    "            # obj with true cost\n",
    "            zpi = np.dot(wpi, c[i])\n",
    "            # round\n",
    "            zpi = zpi.round(1)\n",
    "            zi = z[i,0].round(1)\n",
    "            # regret\n",
    "            regret = (zpi - zi).round(1)\n",
    "            data[\"Regret\"].append(regret)\n",
    "            data[\"Relative Regret\"].append(regret / zi)\n",
    "            # accuracy\n",
    "            data[\"Accuracy\"].append((abs(wpi - w[i]) < 0.5).mean())\n",
    "            # optimal\n",
    "            data[\"Optimal\"].append(abs(regret) < 1e-5)\n",
    "    # dataframe\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    # print\n",
    "    time.sleep(1)\n",
    "    print(\"Avg Regret: {:.4f}\".format(df[\"Regret\"].mean()))\n",
    "    print(\"Avg Rel Regret: {:.2f}%\".format(df[\"Relative Regret\"].mean()*100))\n",
    "    print(\"Path Accuracy: {:.2f}%\".format(df[\"Accuracy\"].mean()*100))\n",
    "    print(\"Optimality Ratio: {:.2f}%\".format(df[\"Optimal\"].mean()*100))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearningCurve(loss_log, regret_log):\n",
    "    # draw loss during training\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(loss_log, color=\"c\")\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.xlim(-100, len(loss_log)+100)\n",
    "    plt.xlabel(\"Iters\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.title(\"Learning Curve on Training Set\", fontsize=12)\n",
    "    plt.show()\n",
    "    # draw normalized regret on test\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot([i*log_step for i in range(len(regret_log))], regret_log, color=\"royalblue\")\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.xlim(-epoch/50, epochs+epoch/50)\n",
    "    plt.ylim(0, max(regret_log[1:])*1.1)\n",
    "    plt.xlabel(\"Epochs\", fontsize=12)\n",
    "    plt.ylabel(\"Normalized Regret\", fontsize=12)\n",
    "    plt.title(\"Learning Curve on Test Set\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87b1f2",
   "metadata": {},
   "source": [
    "## 6 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d89b1",
   "metadata": {},
   "source": [
    "### 6.1 Two-Stage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0c0c6",
   "metadata": {},
   "source": [
    "Two-Stage model: training with MSE of costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96514a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=lr)\n",
    "# set stopper\n",
    "# stopper = earlyStopper(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss\n",
    "mseloss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f758edc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log1, regret_log1 = [], [pyepo.metric.regret(nnet, optmodel, loader_test)]\n",
    "tbar = tqdm(range(epochs))\n",
    "for epoch in tbar:\n",
    "    nnet.train()\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = nnet(x) # predicted cost\n",
    "        loss = mseloss(cp, c) # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        loss_log1.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == int(epochs*0.6)) or (epoch == int(epochs*0.8)):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10\n",
    "    if epoch % log_step == 0:\n",
    "        # log regret\n",
    "        regret = pyepo.metric.regret(nnet, optmodel, loader_test) # regret on test\n",
    "        regret_log1.append(regret)\n",
    "        # early stop\n",
    "        #regret = pyepo.metric.regret(nnet, optmodel, loader_val) # regret on val\n",
    "        #if stopper.stop(regret):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot    \n",
    "plotLearningCurve(loss_log1, regret_log1)\n",
    "# eval \n",
    "print(\"Test set:\")\n",
    "df1 = evaluate(nnet, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a155",
   "metadata": {},
   "source": [
    "### 6.2 Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014fa54",
   "metadata": {},
   "source": [
    "Baseline model: training with binary cross entropy loss of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss\n",
    "bceloss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log2 = []\n",
    "nnet.train()\n",
    "tbar = tqdm(range(150))\n",
    "for epoch in tbar:\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        h = nnet(x)\n",
    "        wp = torch.sigmoid(h)\n",
    "        loss = bceloss(wp, w) # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        loss_log2.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == 90) or (epoch == 120):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab446f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw loss during training\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(loss_log2, color=\"c\")\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlim(-300, len(loss_log2)+300)\n",
    "plt.xlabel(\"Iters\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.title(\"Learning Curve on Training Set\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set:\")\n",
    "# init data\n",
    "data = {\"Accuracy\":[], \"Optimal\":[]}\n",
    "# eval\n",
    "nnet.eval()\n",
    "for x, c, w, z in tqdm(loader_test):\n",
    "    # cuda\n",
    "    if next(nnet.parameters()).is_cuda:\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    # predict\n",
    "    with torch.no_grad(): # no grad\n",
    "        cp = nnet(x)\n",
    "    # to numpy\n",
    "    c = c.to(\"cpu\").detach().numpy()\n",
    "    w = w.to(\"cpu\").detach().numpy()\n",
    "    z = z.to(\"cpu\").detach().numpy()\n",
    "    cp = cp.to(\"cpu\").detach().numpy()\n",
    "    # solve\n",
    "    for i in range(cp.shape[0]):\n",
    "        # sol for pred cost\n",
    "        optmodel.setObj(cp[i])\n",
    "        wpi, _ = optmodel.solve()\n",
    "        # obj with true cost\n",
    "        zpi = np.dot(wpi, c[i])\n",
    "        # round\n",
    "        zpi = zpi.round(1)\n",
    "        zi = z[i,0].round(1)\n",
    "        # regret\n",
    "        regret = (zpi - zi).round(1)\n",
    "        # accuracy\n",
    "        data[\"Accuracy\"].append((abs(wpi - w[i]) < 0.5).mean())\n",
    "        # optimal\n",
    "        data[\"Optimal\"].append(abs(regret) < 1e-2)\n",
    "# dataframe\n",
    "df2 = pd.DataFrame.from_dict(data)\n",
    "# print\n",
    "time.sleep(1)\n",
    "print(\"Path Accuracy: {:.2f}%\".format(df2[\"Accuracy\"].mean()*100))\n",
    "print(\"Optimality Ratio: {:.2f}%\".format(df2[\"Optimal\"].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c8819",
   "metadata": {},
   "source": [
    "### 6.3 SPO+ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b23432",
   "metadata": {},
   "source": [
    "SPO+ model: training with smart predict-then-optimize+ loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad38388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=lr)\n",
    "# set stopper\n",
    "#stopper = earlyStopper(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cde23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss\n",
    "spoploss = pyepo.func.SPOPlus(optmodel, processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log3, regret_log3 = [], [pyepo.metric.regret(nnet, optmodel, loader_test)]\n",
    "tbar = tqdm(range(epochs))\n",
    "for epoch in tbar:\n",
    "    nnet.train()\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = nnet(x) # predicted cost\n",
    "        loss = spoploss(cp, c, w, z).mean() # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log loss\n",
    "        loss_log3.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == int(epochs*0.6)) or (epoch == int(epochs*0.8)):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10\n",
    "    if epoch % log_step == 0:\n",
    "        # log regret\n",
    "        regret = pyepo.metric.regret(nnet, optmodel, loader_test) # regret on test\n",
    "        regret_log3.append(regret)\n",
    "        # early stop\n",
    "        #regret = pyepo.metric.regret(nnet, optmodel, loader_val) # regret on val\n",
    "        #if stopper.stop(regret):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plotLearningCurve(loss_log3, regret_log3)\n",
    "# eval\n",
    "print(\"Test set:\")\n",
    "df3 = evaluate(nnet, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd15a583",
   "metadata": {},
   "source": [
    "### 6.4 DBB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509eb432",
   "metadata": {},
   "source": [
    "DBB model: training with differentiable black-box optimizer and MSE of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=1e-5) \n",
    "# set stopper\n",
    "#stopper = earlyStopper(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f982a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dbb\n",
    "dbb = pyepo.func.blackboxOpt(optmodel, lambd=10, processes=1) \n",
    "# set loss\n",
    "class hammingLoss(torch.nn.Module):\n",
    "    def forward(self, wp, w):\n",
    "        loss = wp * (1.0 - w) + (1.0 - wp) * w\n",
    "        return loss.mean(dim=0).sum()\n",
    "hmloss = hammingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cf53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log4, regret_log4 = [], [pyepo.metric.regret(nnet, optmodel, loader_test)]\n",
    "tbar = tqdm(range(epochs))\n",
    "for epoch in tbar:\n",
    "    nnet.train()\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = nnet(x) # predicted cost\n",
    "        wp = dbb(cp) # black-box optimizer\n",
    "        loss = hmloss(wp, w) # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        loss_log4.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == int(epochs*0.6)) or (epoch == int(epochs*0.8)):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10\n",
    "    if epoch % log_step == 0:\n",
    "        # log regret\n",
    "        regret = pyepo.metric.regret(nnet, optmodel, loader_test) # regret on test\n",
    "        regret_log4.append(regret)\n",
    "        # early stop\n",
    "        #regret = pyepo.metric.regret(nnet, optmodel, loader_val) # regret on val\n",
    "        #if stopper.stop(regret):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dbba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plotLearningCurve(loss_log4,  regret_log4)\n",
    "# eval\n",
    "print(\"Test set:\")\n",
    "df4 = evaluate(nnet, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd3e7f",
   "metadata": {},
   "source": [
    "### 6.5 DPO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5730bace",
   "metadata": {},
   "source": [
    "DPO model: training with differentiable perturbed optimizer and MSE of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7688ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=lr)\n",
    "# set stopper\n",
    "#stopper = earlyStopper(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c344cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dpo\n",
    "ptb = pyepo.func.perturbedOpt(optmodel, n_samples=1, epsilon=1.0, processes=1)\n",
    "# set loss\n",
    "mseloss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6cfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log5, regret_log5 = [], [pyepo.metric.regret(nnet, optmodel, loader_test)]\n",
    "tbar = tqdm(range(epochs))\n",
    "for epoch in tbar:\n",
    "    nnet.train()\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = nnet(x) # predicted cost\n",
    "        we = ptb(cp) # perturbed optimizer\n",
    "        loss = mseloss(we, w) # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        loss_log5.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == int(epochs*0.6)) or (epoch == int(epochs*0.8)):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10\n",
    "    if epoch % log_step == 0:\n",
    "        # log regret\n",
    "        regret = pyepo.metric.regret(nnet, optmodel, loader_test) # regret on test\n",
    "        regret_log5.append(regret)\n",
    "        # early stop\n",
    "        #regret = pyepo.metric.regret(nnet, optmodel, loader_val) # regret on val\n",
    "        #if stopper.stop(regret):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plotLearningCurve(loss_log5, regret_log5)\n",
    "# eval\n",
    "print(\"Test set:\")\n",
    "df5 = evaluate(nnet, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b4904",
   "metadata": {},
   "source": [
    "### 6.6 PFYL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf900e4",
   "metadata": {},
   "source": [
    "PFYL model: training with Perturbed Fenchel-Young loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "nnet = partialResNet(k=12)\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    nnet = nnet.cuda()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=lr)\n",
    "# set stopper\n",
    "#stopper = earlyStopper(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss\n",
    "fyloss = pyepo.func.perturbedFenchelYoung(optmodel, n_samples=1, epsilon=1.0, processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "loss_log6, regret_log6 = [], [pyepo.metric.regret(nnet, optmodel, loader_test)]\n",
    "tbar = tqdm(range(epochs))\n",
    "for epoch in tbar:\n",
    "    nnet.train()\n",
    "    for x, c, w, z in loader_train:\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = nnet(x) # predicted cost\n",
    "        loss = fyloss(cp, w).mean() # loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        loss_log6.append(loss.item())\n",
    "        tbar.set_description(\"Epoch: {:2}, Loss: {:3.4f}\".format(epoch, loss.item()))\n",
    "    # scheduled learning rate\n",
    "    if (epoch == int(epochs*0.6)) or (epoch == int(epochs*0.8)):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= 10\n",
    "    if epoch % log_step == 0:\n",
    "        # log regret\n",
    "        regret = pyepo.metric.regret(nnet, optmodel, loader_test) # regret on test\n",
    "        regret_log6.append(regret)\n",
    "        # early stop\n",
    "        #regret = pyepo.metric.regret(nnet, optmodel, loader_val) # regret on val\n",
    "        #if stopper.stop(regret):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13864fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plotLearningCurve(loss_log6, regret_log6)\n",
    "# eval\n",
    "print(\"Test set:\")\n",
    "df6 = evaluate(nnet, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a41ea0",
   "metadata": {},
   "source": [
    "## 7 Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db133936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "colors = [\"#dd604d\", \"#ee8866\", \"#77aadd\", \"#5aa461\", \"#9970ab\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898a0ee",
   "metadata": {},
   "source": [
    "### 7.1 Learning Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17510694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drow learning curve on test set\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot([i*log_step for i in range(len(regret_log1))], regret_log1, color=colors[0], lw=3, ls=\"-\", label=\"2S\")\n",
    "plt.plot([i*log_step for i in range(len(regret_log3))], regret_log3, color=colors[1], lw=3, ls=\"--\", label=\"SPO+\", )\n",
    "plt.plot([i*log_step for i in range(len(regret_log4))], regret_log4, color=colors[2], lw=3, ls=\"-.\", label=\"DBB\")\n",
    "plt.plot([i*log_step for i in range(len(regret_log5))], regret_log5, color=colors[3], lw=3, ls=\":\", label=\"DPO\")\n",
    "plt.plot([i*log_step for i in range(len(regret_log6))], regret_log6, color=colors[4], lw=3, ls=(0,(3,1,1,1,1,1)), label=\"PFYL\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlim(-1, epochs+1)\n",
    "plt.ylim(-0.05, 1.95)\n",
    "plt.xlabel(\"Epochs\", fontsize=20)\n",
    "plt.ylabel(\"Normalized Regret\", fontsize=20)\n",
    "plt.title(\"Learning Curve on Test Set\", fontsize=20)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83531675",
   "metadata": {},
   "source": [
    "### 7.2 Regret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e59e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxplot of regret per instance\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "boxplot_data = [df1[\"Regret\"], df3[\"Regret\"], df4[\"Regret\"], df5[\"Regret\"], df6[\"Regret\"]]\n",
    "bp = plt.boxplot(boxplot_data, medianprops=dict(color=\"dimgrey\", linewidth=2), patch_artist=True, widths=0.75)\n",
    "for i, patch in enumerate(bp[\"boxes\"]):\n",
    "    patch.set_facecolor(colors[i])\n",
    "    patch.set_color(colors[i])\n",
    "    patch.set_linewidth(4)\n",
    "for i, patch in enumerate(bp[\"whiskers\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(2)\n",
    "for i, patch in enumerate(bp[\"caps\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(3)\n",
    "for i, patch in enumerate(bp[\"fliers\"]):\n",
    "    patch.set_marker(\"o\")\n",
    "    patch.set_markeredgecolor(colors[i])\n",
    "    patch.set_markersize(6)\n",
    "    patch.set_markeredgewidth(2)\n",
    "for i, patch in enumerate(bp[\"medians\"]):\n",
    "    patch.set_color(\"w\")\n",
    "    patch.set_linewidth(2)\n",
    "# grid\n",
    "plt.grid(color=\"grey\", alpha=0.5, linewidth=0.5, which=\"major\", axis=\"y\")\n",
    "# labels and ticks\n",
    "plt.xticks(ticks=range(1,6), fontsize=16, labels=[\"2S\", \"SPO+\", \"DBB\", \"DPO\", \"PFYL\"])\n",
    "plt.xlabel(\"Methods\", fontsize=20)\n",
    "plt.ylabel(\"Regret\", fontsize=20)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.ylim(-0.2, 40)\n",
    "plt.title(\"Regret for each Instance on Test Set\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036eac0f",
   "metadata": {},
   "source": [
    "### 7.3 Relative Regret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a71f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxplot of regret per instance\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "boxplot_data = [df1[\"Relative Regret\"], df3[\"Relative Regret\"], df4[\"Relative Regret\"], \n",
    "                df5[\"Relative Regret\"], df6[\"Relative Regret\"]]\n",
    "bp = plt.boxplot(boxplot_data, medianprops=dict(color=\"dimgrey\", linewidth=2), patch_artist=True, widths=0.75)\n",
    "for i, patch in enumerate(bp[\"boxes\"]):\n",
    "    patch.set_facecolor(colors[i])\n",
    "    patch.set_color(colors[i])\n",
    "    patch.set_linewidth(4)\n",
    "for i, patch in enumerate(bp[\"whiskers\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(2)\n",
    "for i, patch in enumerate(bp[\"caps\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(3)\n",
    "for i, patch in enumerate(bp[\"fliers\"]):\n",
    "    patch.set_marker(\"o\")\n",
    "    patch.set_markeredgecolor(colors[i])\n",
    "    patch.set_markersize(6)\n",
    "    patch.set_markeredgewidth(2)\n",
    "for i, patch in enumerate(bp[\"medians\"]):\n",
    "    patch.set_color(\"w\")\n",
    "    patch.set_linewidth(2)\n",
    "# grid\n",
    "plt.grid(color=\"grey\", alpha=0.5, linewidth=0.5, which=\"major\", axis=\"y\")\n",
    "# labels and ticks\n",
    "plt.xticks(ticks=range(1,6), fontsize=16, labels=[\"2S\", \"SPO+\", \"DBB\", \"DPO\", \"PFYL\"])\n",
    "plt.xlabel(\"Methods\", fontsize=20)\n",
    "plt.ylabel(\"Relative Regret\", fontsize=20)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.ylim(-0.05, 1.8)\n",
    "plt.title(\"Relative Regret for each Instance on Test Set\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99234c01",
   "metadata": {},
   "source": [
    "### 7.4 Path Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxplot of accuracy per instance\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "boxplot_data = [df1[\"Accuracy\"], df3[\"Accuracy\"], df4[\"Accuracy\"], df5[\"Accuracy\"], df6[\"Accuracy\"]]\n",
    "bp = plt.boxplot(boxplot_data, medianprops=dict(color=\"dimgrey\", linewidth=2), patch_artist=True, widths=0.75)\n",
    "for i, patch in enumerate(bp[\"boxes\"]):\n",
    "    patch.set_facecolor(colors[i])\n",
    "    patch.set_color(colors[i])\n",
    "    patch.set_linewidth(4)\n",
    "for i, patch in enumerate(bp[\"whiskers\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(2)\n",
    "for i, patch in enumerate(bp[\"caps\"]):\n",
    "    patch.set_color(colors[i//2])\n",
    "    patch.set_linewidth(3)\n",
    "for i, patch in enumerate(bp[\"fliers\"]):\n",
    "    patch.set_marker(\"o\")\n",
    "    patch.set_markeredgecolor(colors[i])\n",
    "    patch.set_markersize(6)\n",
    "    patch.set_markeredgewidth(2)\n",
    "for i, patch in enumerate(bp[\"medians\"]):\n",
    "    patch.set_color(\"w\")\n",
    "    patch.set_linewidth(2)\n",
    "# grid\n",
    "plt.grid(color=\"grey\", alpha=0.5, linewidth=0.5, which=\"major\", axis=\"y\")\n",
    "# labels and ticks\n",
    "plt.xticks(ticks=range(1,6), fontsize=16, labels=[\"2S\", \"SPO+\", \"DBB\", \"DPO\", \"PFYL\"])\n",
    "plt.xlabel(\"Methods\", fontsize=20)\n",
    "plt.ylabel(\"Path Accuracy\", fontsize=20)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.ylim(0.6, 1.02)\n",
    "plt.title(\"Path Accuracy for each Instance on Test Set\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753fbb5",
   "metadata": {},
   "source": [
    "### 7.4 Optimality Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45710e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw barplot of optimality ratio per instance\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "barplot_data = [df1[\"Optimal\"].mean(), df3[\"Optimal\"].mean(), df4[\"Optimal\"].mean(),\n",
    "                df5[\"Optimal\"].mean(), df6[\"Optimal\"].mean()]\n",
    "bp = plt.bar(range(5), barplot_data, color=colors)\n",
    "# grid\n",
    "plt.grid(color=\"grey\", alpha=0.5, linewidth=0.5, which=\"major\", axis=\"y\")\n",
    "# labels and ticks\n",
    "plt.xticks(ticks=range(5), fontsize=16, labels=[\"2S\", \"SPO+\", \"DBB\", \"DPO\", \"PFYL\"])\n",
    "plt.xlabel(\"Methods\", fontsize=20)\n",
    "plt.ylabel(\"Optimality Ratio\", fontsize=20)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"Optimality Ratio on Test Set\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804030a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
