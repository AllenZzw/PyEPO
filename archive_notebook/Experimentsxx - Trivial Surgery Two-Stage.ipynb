{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d013e448",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d515aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spo.data import trivialsurgery, dataset\n",
    "from spo.model import trivialSurgeryModel\n",
    "from spo.twostage import sklearnPred\n",
    "from spo.eval import calUnambSPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a3b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7b800",
   "metadata": {},
   "source": [
    "## Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec3a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-08-04\n",
      "Using license file /Users/jmosseri/gurobi.lic\n"
     ]
    }
   ],
   "source": [
    "# model for shortest path\n",
    "k = 10\n",
    "num_surgeries = 15\n",
    "sp_model = trivialSurgeryModel(k, num_surgeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2d469",
   "metadata": {},
   "source": [
    "## Build Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f4a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr_twostage = sklearnPred(lr, sp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9f77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf = RandomForestRegressor(random_state=135)\n",
    "rf_twostage = sklearnPred(rf, sp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f245e",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e3b9b",
   "metadata": {},
   "source": [
    "### Training Set Size = 100, Noise Half−width = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d053376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "n = 100 # number of data\n",
    "p = 5 # size of feature\n",
    "e = 0 # noise half−width\n",
    "degs = [1, 2, 4, 6] # list of param deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1799164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init DataFrame\n",
    "df1_lr = pd.DataFrame(columns = degs)\n",
    "df1_rf = pd.DataFrame(columns = degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e5220c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1238.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1586.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 455.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized SPO Loss: 0.00%\n",
      "\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1446.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1620.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 487.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized SPO Loss: 0.05%\n",
      "\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1441.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1674.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 437.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-962f1bd6da02>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mcalUnambSPO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msp_model\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_pred_i\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_true_i\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mz_true_i\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m/=\u001B[0m \u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msp_dataset_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mz\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Normalized SPO Loss: {:.2f}%'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdeg\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        lr_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = lr_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df1_lr = df1_lr.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df1_lr, boxprops=dict(facecolor='g', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 100,\\nNoise Half−width = 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfde9f5",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        rf_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = rf_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df1_rf = df1_rf.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acb525",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df1_lr, boxprops=dict(facecolor='r', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 100,\\nNoise Half−width = 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95594a",
   "metadata": {},
   "source": [
    "### Training Set Size = 100, Noise Half−width = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9bf12",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# set up\n",
    "n = 100 # number of data\n",
    "p = 5 # size of feature\n",
    "e = 0.5 # noise half−width\n",
    "degs = [1, 2, 4, 6] # list of param deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e756a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# init DataFrame\n",
    "df2_lr = pd.DataFrame(columns = degs)\n",
    "df2_rf = pd.DataFrame(columns = degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc5298",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        lr_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = lr_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df2_lr = df2_lr.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c17bab",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df2_lr, boxprops=dict(facecolor='g', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 100,\\nNoise Half−width = 0.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b7ae1",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        rf_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = rf_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df2_rf = df2_rf.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccc751",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df2_rf, boxprops=dict(facecolor='r', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 100,\\nNoise Half−width = 0.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad062d56",
   "metadata": {},
   "source": [
    "### Training Set Size = 1000, Noise Half−width = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d91ae",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# set up\n",
    "n = 1000 # number of data\n",
    "p = 5 # size of feature\n",
    "e = 0 # noise half−width\n",
    "degs = [1, 2, 4, 6] # list of param deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47249991",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# init DataFrame\n",
    "df3_lr = pd.DataFrame(columns = degs)\n",
    "df3_rf = pd.DataFrame(columns = degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab73ce",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        lr_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = lr_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df3_lr = df3_lr.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46220d41",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df3_lr, boxprops=dict(facecolor='g', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 1000,\\nNoise Half−width = 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132582e8",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        rf_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = rf_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df3_rf = df3_rf.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd269f8c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df3_rf, boxprops=dict(facecolor='r', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 1000,\\nNoise Half−width = 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062d585",
   "metadata": {},
   "source": [
    "### Training Set Size = 1000, Noise Half−width = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c8044",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# set up\n",
    "n = 1000 # number of data\n",
    "p = 5 # size of feature\n",
    "e = 0.5 # noise half−width\n",
    "degs = [1, 2, 4, 6] # list of param deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0f70e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# init DataFrame\n",
    "df4_lr = pd.DataFrame(columns = degs)\n",
    "df4_rf = pd.DataFrame(columns = degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09895ac1",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        lr_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = lr_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df4_lr = df4_lr.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28b217",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df4_lr, boxprops=dict(facecolor='g', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 1000,\\nNoise Half−width = 0.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06812291",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    row = {}\n",
    "    for deg in degs:\n",
    "        # generate data\n",
    "        x, c = trivialsurgery.genData(n+1000, p, num_surgeries, deg=deg, noise_width=e, seed=i)\n",
    "        # data split\n",
    "        x_train, x_test, c_train, c_test = train_test_split(x, c, test_size=1000, random_state=i)\n",
    "        # build data set\n",
    "        sp_dataset_train = dataset.optDataset(sp_model, x_train, c_train)\n",
    "        sp_dataset_test = dataset.optDataset(sp_model, x_test, c_test)\n",
    "        # training\n",
    "        rf_twostage.fit(sp_dataset_train.x, sp_dataset_train.c)\n",
    "        # prediction\n",
    "        c_test_pred = rf_twostage.predict(sp_dataset_test.x)\n",
    "        # eval\n",
    "        loss = 0\n",
    "        print('Evaluate....')\n",
    "        time.sleep(1)\n",
    "        for j in tqdm(range(1000)):\n",
    "            c_pred_i = c_test_pred[j]\n",
    "            c_true_i = sp_dataset_test.c[j]\n",
    "            z_true_i = sp_dataset_test.z[j,0]\n",
    "            loss += calUnambSPO(sp_model, c_pred_i, c_true_i, z_true_i)\n",
    "        loss /= abs(sp_dataset_test.z).sum()\n",
    "        time.sleep(1)\n",
    "        print('Normalized SPO Loss: {:.2f}%'.format(loss * 100))\n",
    "        row[deg] = loss\n",
    "        print()\n",
    "    df4_rf = df4_rf.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751008b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw boxplot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(df4_rf, boxprops=dict(facecolor='r', color='k'), medianprops=dict(color='k'), patch_artist=True)\n",
    "plt.xlabel('Deg', fontsize=16)\n",
    "plt.xticks(ticks=[1,2,3,4], labels=[1,2,4,6], fontsize=12)\n",
    "plt.ylabel('Normalized SPO Loss', fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title('Training Set Size = 1000,\\nNoise Half−width = 0.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143768ba",
   "metadata": {},
   "source": [
    "## Save File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ac162",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df1_lr.to_csv('./res/ts/lr_n100.csv', index=False)\n",
    "df1_rf.to_csv('./res/ts/rf_n100.csv', index=False)\n",
    "df2_lr.to_csv('./res/ts/lr_n100_noise.csv', index=False)\n",
    "df2_rf.to_csv('./res/ts/rf_n100_noise.csv', index=False)\n",
    "df3_lr.to_csv('./res/ts/lr_n1000.csv', index=False)\n",
    "df3_rf.to_csv('./res/ts/rf_n1000.csv', index=False)\n",
    "df4_lr.to_csv('./res/ts/lr_n1000_noise.csv', index=False)\n",
    "df4_rf.to_csv('./res/ts/rf_n1000_noise.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8857063",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}